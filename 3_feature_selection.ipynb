{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72d58cee-1b5e-4df8-bbbd-f99460844b6e",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "On this part we are going to try to reduce the complexity and the correlation of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7f45582-81ff-484f-acd5-26a6432b967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e592cf6-c84f-484b-b215-1d24148d34e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"transformed_train.csv\")\n",
    "data_test = pd.read_csv(\"transformed_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e466e44d-04fd-47e8-a147-ece8e5ae9d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_1.0</th>\n",
       "      <th>Pclass_2.0</th>\n",
       "      <th>Pclass_3.0</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.566474</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283740</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070118</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.061045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.258608</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484795</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.509927</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.170646</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.234224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258608</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.150855</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived       Age  SibSp     Parch      Fare  Sex_male  Pclass_1.0  \\\n",
       "0         0.0  0.566474  0.000  0.000000  0.055628       1.0         1.0   \n",
       "1         0.0  0.283740  0.000  0.000000  0.025374       1.0         0.0   \n",
       "2         0.0  0.396833  0.000  0.000000  0.015469       1.0         0.0   \n",
       "3         0.0  0.321438  0.125  0.000000  0.015330       1.0         0.0   \n",
       "4         0.0  0.070118  0.500  0.333333  0.061045       0.0         0.0   \n",
       "..        ...       ...    ...       ...       ...       ...         ...   \n",
       "707       1.0  0.258608  0.000  0.000000  0.014932       0.0         0.0   \n",
       "708       0.0  0.484795  0.000  0.000000  0.060508       1.0         1.0   \n",
       "709       0.0  0.509927  0.250  0.000000  0.027538       1.0         0.0   \n",
       "710       1.0  0.170646  0.125  0.333333  0.234224       0.0         1.0   \n",
       "711       0.0  0.258608  0.000  0.166667  0.150855       1.0         1.0   \n",
       "\n",
       "     Pclass_2.0  Pclass_3.0  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           0.0         0.0         0.0         0.0         1.0  \n",
       "1           1.0         0.0         0.0         0.0         1.0  \n",
       "2           0.0         1.0         0.0         0.0         1.0  \n",
       "3           0.0         1.0         0.0         0.0         1.0  \n",
       "4           0.0         1.0         0.0         0.0         1.0  \n",
       "..          ...         ...         ...         ...         ...  \n",
       "707         0.0         1.0         0.0         0.0         1.0  \n",
       "708         0.0         0.0         0.0         0.0         1.0  \n",
       "709         0.0         1.0         0.0         0.0         1.0  \n",
       "710         0.0         0.0         0.0         0.0         1.0  \n",
       "711         0.0         0.0         0.0         0.0         1.0  \n",
       "\n",
       "[712 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eb8b8c-101c-4d20-be4b-45d1c893943d",
   "metadata": {},
   "source": [
    "On this point we have two alternative ways of doing feature selection.\n",
    "\n",
    "* Selecting among the columns we have\n",
    "* Dimensionality reduction techniques\n",
    "\n",
    "On this notebook I am going to follow the first aproach.\n",
    "\n",
    "For this, we are going to employ the minimun redundancy maximun relevance (with the mutual information criterion as relevance and the correlation as redundancy) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a326dde3-c8f0-43bc-8c7c-dbaeca785b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Precomputing the relevances, and the redundancy\n",
    "relevance = mutual_info_regression(data_train.drop(\"Survived\", axis=1), data_train.Survived)\n",
    "redundancy = np.abs(np.cov(data_train.drop(\"Survived\", axis=1)))\n",
    "\n",
    "m = len(relevance)\n",
    "\n",
    "# List of features selected with the first already selected\n",
    "features = [np.argmax(relevance)]\n",
    "MRmr_score = [np.max(relevance)]\n",
    "\n",
    "candidates = np.arange(m)\n",
    "selected = np.array([])\n",
    "\n",
    "# adding the first feature\n",
    "f = np.argmax(relevance)\n",
    "selected = np.hstack([candidates[f]])\n",
    "candidates = np.delete(candidates, f)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(m-1):\n",
    "    rel = relevance[candidates]\n",
    "    \n",
    "    #Average of the covariation coefficient of the current candidates and the selected features\n",
    "    red = np.sum(redundancy[np.ix_(selected, candidates)], axis=0)\n",
    "    \n",
    "    mrmr = rel-red\n",
    "    \n",
    "    # Select the next feature\n",
    "    f = np.argmax(mrmr)\n",
    "    \n",
    "    #Update the candidates and selected features\n",
    "    features.append(candidates[f])\n",
    "    MRmr_score.append(mrmr[f])\n",
    "    selected = np.hstack([selected, candidates[f]])\n",
    "    candidates = np.delete(candidates, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f2a1da6-77e1-4e8b-9b18-e1045f394153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex_male      0.127039\n",
       "Age           0.022676\n",
       "Embarked_S   -0.044543\n",
       "Pclass_3.0   -0.109239\n",
       "Fare         -0.175583\n",
       "Pclass_1.0   -0.346850\n",
       "Parch        -0.431950\n",
       "Embarked_Q   -0.571950\n",
       "SibSp        -0.686125\n",
       "Pclass_2.0   -0.894244\n",
       "Embarked_C   -1.021141\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MRmr_features = pd.Series(MRmr_score, index=data_train.drop(\"Survived\", axis=1).columns[features]) \n",
    "MRmr_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e9ffbb-d309-439c-b0ba-1e9da80eb242",
   "metadata": {},
   "source": [
    "We can appreciate that this more of less confirms what we have seen on the exploratory part. The most critical variable is the sex. Then the age. Then the class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb3de9-e31c-4912-b0d3-64014189b1fd",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "Given that we do not have that many features, it is not that critical to remove data features. We are going to remove them if that increases the performance. But for now they keep the same and use these results as reference.\n",
    "\n",
    "Also we must comment that there exist a lot of techniques which do feature selection. Most of the time they do a simmilar ranking. However there is not clear evidance that one performs better than others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba24385-1992-42ef-a4dd-f7334d6c7628",
   "metadata": {},
   "source": [
    "We are going to define a function which mesures the score of the model given a set of features for training.\n",
    "\n",
    "As model we are going to use a Random forest classifier since it is one of the most robust models we can use. \n",
    "In addition we are going to perform a gridsearch in order to tune the models.\n",
    "\n",
    "The score will be the best accuracy gotten from the gridsearch with the given set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcae9dba-f015-4a1b-9e40-ed02b60ac7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def score_model(data_train, features):\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "    gs = GridSearchCV(model, param_grid={'max_depth': [1,2,3,4,5,6,7,8,9,10], 'n_estimators':range(10,150,20)}, scoring='roc_auc', cv=5)\n",
    "    gs.fit(data_train[features], data_train[\"Survived\"])\n",
    "    return gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba1bc4c",
   "metadata": {},
   "source": [
    "We are going to perform a recursive feature elimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42569f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best score is 0.8652297656802638 \n",
      " Current selected features are ['Age' 'SibSp' 'Parch' 'Fare' 'Sex_male' 'Pclass_2.0' 'Pclass_3.0'\n",
      " 'Embarked_C' 'Embarked_Q' 'Embarked_S']\n",
      "Current best score is 0.8652297656802638 \n",
      " Current selected features are ['Age' 'SibSp' 'Parch' 'Fare' 'Sex_male' 'Pclass_2.0' 'Pclass_3.0'\n",
      " 'Embarked_C' 'Embarked_Q' 'Embarked_S']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Age', 'SibSp', 'Parch', 'Fare', 'Sex_male', 'Pclass_2.0',\n",
       "       'Pclass_3.0', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inverse recursive feature elimination\n",
    "def inverse_rfe(data_train):\n",
    "    features = data_train.columns.values\n",
    "    features = np.delete(features, np.where(features == \"Survived\"))\n",
    "    best_score = score_model(data_train, features)\n",
    "    best_features = features\n",
    "\n",
    "    updated = True\n",
    "    while len(features) > 1 and updated:\n",
    "        updated = False\n",
    "        for feature in features:\n",
    "            features_ = features.copy()\n",
    "            features_ = np.delete(features_, np.where(features_ == feature))\n",
    "            score = score_model(data_train, features_)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_features = features_\n",
    "                updated = True\n",
    "\n",
    "        print(f\"Current best score is {best_score} \\n Current selected features are {best_features}\")\n",
    "        features = best_features\n",
    "\n",
    "    return best_features\n",
    "\n",
    "inverse_rfe(data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b39992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "635bfcee",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "At the end the features we are going tune are:\n",
    "\n",
    "\n",
    "This gives us an accuracy of more or less xxx percent\n",
    "\n",
    "Finally, we are going to do a more intense gridsearch. And we are going to create our pipeline. That way we can automatize all the steps we have done through this notebook."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
