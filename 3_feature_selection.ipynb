{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72d58cee-1b5e-4df8-bbbd-f99460844b6e",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "On this part we are going to try to reduce the complexity and the correlation of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7f45582-81ff-484f-acd5-26a6432b967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e592cf6-c84f-484b-b215-1d24148d34e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"transformed_train.csv\")\n",
    "data_test = pd.read_csv(\"transformed_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e466e44d-04fd-47e8-a147-ece8e5ae9d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_1.0</th>\n",
       "      <th>Pclass_2.0</th>\n",
       "      <th>Pclass_3.0</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.566474</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283740</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070118</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.061045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.258608</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484795</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.509927</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.170646</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.234224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258608</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.150855</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived       Age  SibSp     Parch      Fare  Sex_male  Pclass_1.0  \\\n",
       "0         0.0  0.566474  0.000  0.000000  0.055628       1.0         1.0   \n",
       "1         0.0  0.283740  0.000  0.000000  0.025374       1.0         0.0   \n",
       "2         0.0  0.396833  0.000  0.000000  0.015469       1.0         0.0   \n",
       "3         0.0  0.321438  0.125  0.000000  0.015330       1.0         0.0   \n",
       "4         0.0  0.070118  0.500  0.333333  0.061045       0.0         0.0   \n",
       "..        ...       ...    ...       ...       ...       ...         ...   \n",
       "707       1.0  0.258608  0.000  0.000000  0.014932       0.0         0.0   \n",
       "708       0.0  0.484795  0.000  0.000000  0.060508       1.0         1.0   \n",
       "709       0.0  0.509927  0.250  0.000000  0.027538       1.0         0.0   \n",
       "710       1.0  0.170646  0.125  0.333333  0.234224       0.0         1.0   \n",
       "711       0.0  0.258608  0.000  0.166667  0.150855       1.0         1.0   \n",
       "\n",
       "     Pclass_2.0  Pclass_3.0  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           0.0         0.0         0.0         0.0         1.0  \n",
       "1           1.0         0.0         0.0         0.0         1.0  \n",
       "2           0.0         1.0         0.0         0.0         1.0  \n",
       "3           0.0         1.0         0.0         0.0         1.0  \n",
       "4           0.0         1.0         0.0         0.0         1.0  \n",
       "..          ...         ...         ...         ...         ...  \n",
       "707         0.0         1.0         0.0         0.0         1.0  \n",
       "708         0.0         0.0         0.0         0.0         1.0  \n",
       "709         0.0         1.0         0.0         0.0         1.0  \n",
       "710         0.0         0.0         0.0         0.0         1.0  \n",
       "711         0.0         0.0         0.0         0.0         1.0  \n",
       "\n",
       "[712 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eb8b8c-101c-4d20-be4b-45d1c893943d",
   "metadata": {},
   "source": [
    "On this point we have two alternative ways of doing feature selection.\n",
    "\n",
    "* Selecting among the columns we have\n",
    "* Dimensionality reduction techniques\n",
    "\n",
    "On this notebook I am going to follow the first aproach.\n",
    "\n",
    "For this, we are going to employ the minimun redundancy maximun relevance (with the mutual information criterion as relevance and the correlation as redundancy) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a326dde3-c8f0-43bc-8c7c-dbaeca785b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Precomputing the relevances, and the redundancy\n",
    "relevance = mutual_info_regression(data_train.drop(\"Survived\", axis=1), data_train.Survived)\n",
    "redundancy = np.abs(np.cov(data_train.drop(\"Survived\", axis=1)))\n",
    "\n",
    "m = len(relevance)\n",
    "\n",
    "# List of features selected with the first already selected\n",
    "features = [np.argmax(relevance)]\n",
    "MRmr_score = [np.max(relevance)]\n",
    "\n",
    "candidates = np.arange(m)\n",
    "selected = np.array([])\n",
    "\n",
    "# adding the first feature\n",
    "f = np.argmax(relevance)\n",
    "selected = np.hstack([candidates[f]])\n",
    "candidates = np.delete(candidates, f)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(m-1):\n",
    "    rel = relevance[candidates]\n",
    "    \n",
    "    #Average of the covariation coefficient of the current candidates and the selected features\n",
    "    red = np.sum(redundancy[np.ix_(selected, candidates)], axis=0)\n",
    "    \n",
    "    mrmr = rel-red\n",
    "    \n",
    "    # Select the next feature\n",
    "    f = np.argmax(mrmr)\n",
    "    \n",
    "    #Update the candidates and selected features\n",
    "    features.append(candidates[f])\n",
    "    MRmr_score.append(mrmr[f])\n",
    "    selected = np.hstack([selected, candidates[f]])\n",
    "    candidates = np.delete(candidates, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f2a1da6-77e1-4e8b-9b18-e1045f394153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex_male      0.162580\n",
       "Pclass_2.0    0.043688\n",
       "Pclass_3.0   -0.058944\n",
       "Fare         -0.112925\n",
       "Embarked_S   -0.154490\n",
       "Pclass_1.0   -0.293595\n",
       "Parch        -0.435539\n",
       "Embarked_Q   -0.571901\n",
       "SibSp        -0.689790\n",
       "Age          -0.893840\n",
       "Embarked_C   -1.021141\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MRmr_features = pd.Series(MRmr_score, index=data_train.drop(\"Survived\", axis=1).columns[features]) \n",
    "MRmr_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e9ffbb-d309-439c-b0ba-1e9da80eb242",
   "metadata": {},
   "source": [
    "We can appreciate that this more of less confirms what we have seen on the exploratory part. The most critical variable is the sex. Then the age. Then the class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb3de9-e31c-4912-b0d3-64014189b1fd",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "Given that we do not have that many features, it is not that critical to remove data features. We are going to remove them if that increases the performance. But for now they keep the same and use these results as reference.\n",
    "\n",
    "Also we must comment that there exist a lot of techniques which do feature selection. Most of the time they do a simmilar ranking. However there is not clear evidance that one performs better than others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba24385-1992-42ef-a4dd-f7334d6c7628",
   "metadata": {},
   "source": [
    "We are going to define a function which mesures the score of the model given a set of features for training.\n",
    "\n",
    "As model we are going to use a Random forest classifier since it is one of the most robust models we can use. \n",
    "In addition we are going to perform a gridsearch in order to tune the models.\n",
    "\n",
    "The score will be the best accuracy gotten from the gridsearch with the given set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcae9dba-f015-4a1b-9e40-ed02b60ac7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def score_model(data_train, features):\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "    gs = GridSearchCV(model, param_grid={'max_depth': [1,2,3,4,5,6,7,8,9,10]}, scoring='roc_auc', cv=5)\n",
    "    gs.fit(data_train[features], data_train[\"Survived\"])\n",
    "    return gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba1bc4c",
   "metadata": {},
   "source": [
    "We are going to perform a recursive feature elimination.\n",
    "In other words:\n",
    "* We are going to score our model trained with all the features. \n",
    "* After that, we are going to score all the models that can be trained with \"total features\" - 1 features. \n",
    "* Then we will pick the features of the one which maximizes the score. \n",
    "\n",
    "And we will repeat the two last steps until we can not improve our score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42569f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best score is 0.8628692407789291 \n",
      " Current selected features are ['Age' 'SibSp' 'Fare' 'Sex_male' 'Pclass_1.0' 'Pclass_2.0' 'Pclass_3.0'\n",
      " 'Embarked_C' 'Embarked_Q' 'Embarked_S']\n",
      "Current best score is 0.8653449733002414 \n",
      " Current selected features are ['Age' 'SibSp' 'Fare' 'Sex_male' 'Pclass_1.0' 'Pclass_3.0' 'Embarked_C'\n",
      " 'Embarked_Q' 'Embarked_S']\n",
      "Current best score is 0.8654001457226494 \n",
      " Current selected features are ['Age' 'SibSp' 'Sex_male' 'Pclass_1.0' 'Pclass_3.0' 'Embarked_C'\n",
      " 'Embarked_Q' 'Embarked_S']\n",
      "Current best score is 0.8670145201574077 \n",
      " Current selected features are ['Age' 'SibSp' 'Sex_male' 'Pclass_1.0' 'Pclass_3.0' 'Embarked_C'\n",
      " 'Embarked_Q']\n"
     ]
    }
   ],
   "source": [
    "# inverse recursive feature elimination\n",
    "def inverse_rfe(data_train):\n",
    "    features = data_train.columns.values\n",
    "    features = np.delete(features, np.where(features == \"Survived\"))\n",
    "    best_score = score_model(data_train, features)\n",
    "    best_features = features\n",
    "\n",
    "    updated = True\n",
    "    while len(features) > 1 and updated:\n",
    "        updated = False\n",
    "        for feature in features:\n",
    "            features_ = features.copy()\n",
    "            features_ = np.delete(features_, np.where(features_ == feature))\n",
    "            score = score_model(data_train, features_)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_features = features_\n",
    "                updated = True\n",
    "        if updated:\n",
    "            print(f\"Current best score is {best_score} \\n Current selected features are {best_features}\")\n",
    "            features = best_features\n",
    "\n",
    "    return features\n",
    "\n",
    "best_features = inverse_rfe(data_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635bfcee",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "At the end the features we are going tune are: 'Age' 'SibSp' 'Sex_male' 'Pclass_1.0' 'Pclass_3.0' 'Embarked_C'\n",
    " 'Embarked_Q'\n",
    "\n",
    "\n",
    "This gives us an accuracy of more or less 86.7 percent\n",
    "\n",
    "We can see that the Recursive feature elimination (RFE) and the Minimun redundancy maximun relevance do not quite concide. However, the features they remove are related to the ones which are not. For instance, Embarked_C should be removed according MRmr and Embarked_S should be removed according to RFE. Something simmilar happens in the case of Pclass.\n",
    "\n",
    "Thinking about this. It makes all the sense of the world. From the feature transforming part, when we encoded our categotical variables (embarked and pclass, in the case of sex we just keep one column) we got 3 binary columns. The thing is that we do not need three binary columns. We can represent the same information using 2 columns. if it is not pclass1 (0) nor pclass3 (0), then it is pclass2.\n",
    "\n",
    "\n",
    "This is the end of the feature selection part. \n",
    "On the next notebook, we are going to do a more intense gridsearch. And we are going to create our pipeline. That way we can automatize all the steps we have done through these notebooks.\n",
    "\n",
    "Let's store our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29afea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[best_features].to_csv(\"transformed_train2.csv\")\n",
    "data_test[best_features].to_csv(\"transformed_test2.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
